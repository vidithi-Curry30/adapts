\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{cite}

\title{\textbf{Enhancing Time Series Foundation Models with Adaptive Local Forecasting and Conformal Prediction: A Comparative Analysis}}

\author{Anonymous Author(s)}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Time series foundation models (FMs) have demonstrated remarkable zero-shot forecasting capabilities across diverse domains. However, their inability to adapt to local patterns in real-time limits their effectiveness for non-stationary data with distribution shifts. This paper presents a comprehensive evaluation of AdapTS, a lightweight adaptation method that enables foundation models to learn dataset-specific patterns through online ridge regression on FFT-transformed features, combined with conformal prediction for uncertainty quantification. We conduct extensive experiments comparing three configurations: (1) FM + Conformal Prediction, (2) AdapTS + Conformal Prediction, and (3) FM + AdapTS + Conformal Prediction across seven stock market datasets. Furthermore, we evaluate these approaches using Amazon's Chronos model, a domain-agnostic foundation model not trained on financial data. Our results demonstrate that AdapTS provides substantial improvements, achieving 60-70\% MAE reduction when combined with Chronos while maintaining 90\% prediction interval coverage. Notably, AdapTS alone with conformal prediction performs competitively with the full system, suggesting that local adaptation captures complementary patterns to those learned by foundation models. These findings indicate that lightweight adaptation methods can significantly enhance the practical utility of foundation models for time series forecasting, particularly in domains requiring reliable uncertainty quantification.
\end{abstract}

\section{Introduction}

Time series forecasting is a fundamental problem with applications spanning finance, healthcare, climate science, and industrial systems. Recent advances in deep learning have led to the development of time series foundation models (FMs)~\cite{zhou2021informer, nie2022time, das2023decoder, ansari2024chronos}---large-scale models pre-trained on diverse datasets that can perform zero-shot forecasting on unseen time series. These models have demonstrated impressive generalization capabilities, often outperforming domain-specific models without requiring task-specific training.

Despite their success, foundation models face critical limitations in real-world deployment. First, they are \textit{static}: once trained, they cannot adapt to local patterns or distribution shifts in the target time series without expensive retraining. Second, they typically provide only point predictions without reliable uncertainty estimates, which are crucial for risk-sensitive applications such as financial trading, resource allocation, and safety-critical systems. Third, their effectiveness in domains significantly different from their training data remains uncertain.

Recent work by~\cite{liu2025adapts} introduced AdapTS, a lightweight method that enables foundation models to adapt online without retraining. AdapTS combines FM predictions with a local forecaster trained via online ridge regression on frequency-domain features. However, several questions remain unanswered:

\begin{enumerate}
    \item How do different combinations of FMs, AdapTS, and conformal prediction compare in terms of accuracy and uncertainty quantification?
    \item Can AdapTS improve domain-agnostic foundation models (e.g., Chronos) that were not trained on the target domain?
    \item Is the foundation model necessary, or can local adaptation alone provide competitive performance?
    \item How do these methods perform across different market conditions and assets?
\end{enumerate}

This paper addresses these questions through a comprehensive experimental study. We implement and evaluate three configurations: (1) \textbf{FM + Conformal}: baseline foundation model with conformal prediction, (2) \textbf{AdapTS + Conformal}: local adaptation without FM guidance, and (3) \textbf{FM + AdapTS + Conformal}: the full system combining all components. We test these approaches on seven diverse stock market datasets (GOOGL, MSFT, WMT, COST, USO, CVX, UNH) spanning technology, retail, energy, and healthcare sectors from 2015-2024.

Our key contributions are:

\begin{itemize}
    \item \textbf{Comprehensive comparative analysis}: We provide the first systematic comparison of FM-only, AdapTS-only, and combined approaches with rigorous uncertainty quantification via conformal prediction.

    \item \textbf{Domain-agnostic evaluation}: We demonstrate that AdapTS provides substantial improvements (60-70\% MAE reduction) even when combined with Chronos, a model not trained on financial data, highlighting its value for domain transfer.

    \item \textbf{Empirical insights}: We show that AdapTS alone performs nearly as well as the full system, suggesting it captures complementary local patterns that foundation models miss, while all methods maintain reliable 90\% coverage.

    \item \textbf{Open-source implementation}: We release our complete implementation, enabling reproducibility and facilitating future research.
\end{itemize}

The remainder of this paper is organized as follows: Section~\ref{sec:related} reviews related work on time series forecasting, foundation models, and uncertainty quantification. Section~\ref{sec:methodology} describes the technical details of AdapTS and conformal prediction with full mathematical formulations. Section~\ref{sec:experiments} presents our experimental setup. Section~\ref{sec:results} reports our findings. Section~\ref{sec:discussion} discusses implications and limitations. Section~\ref{sec:conclusion} concludes.

\section{Related Work}
\label{sec:related}

\subsection{Time Series Foundation Models}

Foundation models for time series have emerged as a powerful paradigm for forecasting. Early work focused on Transformer-based architectures such as Informer~\cite{zhou2021informer}, Autoformer~\cite{wu2021autoformer}, and FEDformer~\cite{zhou2022fedformer}, which addressed the quadratic complexity of attention mechanisms for long sequences. More recently, large-scale pre-trained models have been developed, including TimeGPT~\cite{garza2023timegpt}, which leverages autoregressive prediction on massive time series corpora, and Lag-Llama~\cite{rasul2023lag}, which adapts language model architectures for time series.

Chronos~\cite{ansari2024chronos} represents a notable advance by framing time series forecasting as a language modeling problem, training T5 models on diverse datasets through tokenization. This enables zero-shot forecasting across domains. However, these models are fundamentally static---they cannot adapt to local patterns without retraining, limiting their effectiveness for non-stationary data.

\subsection{Online Learning and Adaptation}

Online learning methods have a rich history in time series forecasting. Classical approaches include exponential smoothing~\cite{hyndman2008forecasting}, ARIMA models with recursive parameter updates~\cite{box2015time}, and Kalman filtering~\cite{kalman1960new}. More recent work has explored online neural networks, including continual learning approaches~\cite{hadsell2020embracing} and meta-learning methods~\cite{finn2017model}.

AdapTS~\cite{liu2025adapts} bridges the gap between foundation models and online learning by introducing a lightweight local forecaster that learns dataset-specific patterns via ridge regression on FFT features. The key innovation is an adaptive weighting mechanism that dynamically balances FM and local predictions based on recent performance. Our work extends this by systematically evaluating different combinations and adding rigorous uncertainty quantification.

\subsection{Uncertainty Quantification}

Reliable uncertainty estimates are essential for decision-making under uncertainty. Traditional approaches include Bayesian methods~\cite{rasmussen2006gaussian}, Monte Carlo dropout~\cite{gal2016dropout}, and ensemble methods~\cite{lakshminarayanan2017simple}. However, these methods are computationally expensive and often poorly calibrated.

Conformal prediction~\cite{vovk2005algorithmic, shafer2008tutorial} provides distribution-free uncertainty quantification with finite-sample coverage guarantees. Recent work has adapted conformal prediction for time series~\cite{xu2021conformal, zaffran2022adaptive}, addressing challenges such as temporal dependence and distribution shift. We employ adaptive conformal prediction to ensure reliable prediction intervals across all evaluated methods.

\section{Methodology}
\label{sec:methodology}

We now describe the technical components of our approach: the AdapTS local forecaster, the adaptive weighting mechanism, and conformal prediction for uncertainty quantification.

\subsection{Problem Formulation}

Consider a univariate time series $\{y_t\}_{t=1}^T$. At time $t$, we observe a context window $\mathbf{x}_t = [y_{t-L+1}, \ldots, y_t] \in \mathbb{R}^L$ of length $L$ and aim to predict the next $H$ values $\mathbf{y}_{t+1:t+H} = [y_{t+1}, \ldots, y_{t+H}] \in \mathbb{R}^H$. We assume access to:

\begin{enumerate}
    \item A pre-trained foundation model $f_{\text{FM}}: \mathbb{R}^L \to \mathbb{R}^H$ that produces zero-shot predictions.
    \item Historical observations that arrive sequentially, enabling online learning.
\end{enumerate}

Our goal is to produce: (1) accurate point forecasts $\hat{\mathbf{y}}_{t+1:t+H}$, and (2) prediction intervals $[\mathbf{l}_{t+1:t+H}, \mathbf{u}_{t+1:t+H}]$ with guaranteed coverage $\mathbb{P}(\mathbf{y}_{t+1:t+H} \in [\mathbf{l}, \mathbf{u}]) \geq 1-\alpha$ for a user-specified miscoverage rate $\alpha$ (e.g., $\alpha=0.1$ for 90\% coverage).

\subsection{AdapTS Local Forecaster}

The AdapTS local forecaster learns dataset-specific patterns through online ridge regression on frequency-domain features.

\subsubsection{Feature Extraction via FFT}

Given a context window $\mathbf{x}_t \in \mathbb{R}^L$, we compute the Fast Fourier Transform (FFT):

\begin{equation}
\mathbf{X}_t = \text{FFT}(\mathbf{x}_t) = \sum_{k=0}^{L-1} x_{t,k} e^{-2\pi i k / L}
\end{equation}

We extract the magnitude spectrum of the first $L/2$ components (positive frequencies), yielding feature vector $\boldsymbol{\phi}(\mathbf{x}_t) \in \mathbb{R}^{L/2}$:

\begin{equation}
\boldsymbol{\phi}(\mathbf{x}_t) = [|\mathbf{X}_t[0]|, |\mathbf{X}_t[1]|, \ldots, |\mathbf{X}_t[L/2-1]|]
\end{equation}

The FFT captures periodic patterns, trends, and spectral characteristics that are often informative for forecasting, while reducing dimensionality from $L$ to $L/2$.

\subsubsection{Online Ridge Regression}

We maintain a sliding window $\mathcal{W}_t$ of size $W$ containing the most recent $W$ feature-target pairs:

\begin{equation}
\mathcal{W}_t = \{(\boldsymbol{\phi}(\mathbf{x}_{t-W+1}), \mathbf{y}_{t-W+1}), \ldots, (\boldsymbol{\phi}(\mathbf{x}_t), \mathbf{y}_t)\}
\end{equation}

At each timestep, we solve the ridge regression problem:

\begin{equation}
\mathbf{W}_t^* = \arg\min_{\mathbf{W}} \sum_{(\boldsymbol{\phi}, \mathbf{y}) \in \mathcal{W}_t} \|\mathbf{y} - \mathbf{W}^\top \boldsymbol{\phi}\|_2^2 + \lambda \|\mathbf{W}\|_F^2
\end{equation}

where $\mathbf{W} \in \mathbb{R}^{(L/2) \times H}$ is the weight matrix mapping features to predictions, and $\lambda > 0$ is the regularization parameter. The closed-form solution is:

\begin{equation}
\mathbf{W}_t^* = (\boldsymbol{\Phi}_t^\top \boldsymbol{\Phi}_t + \lambda \mathbf{I})^{-1} \boldsymbol{\Phi}_t^\top \mathbf{Y}_t
\end{equation}

where $\boldsymbol{\Phi}_t \in \mathbb{R}^{W \times (L/2)}$ stacks all feature vectors in $\mathcal{W}_t$ and $\mathbf{Y}_t \in \mathbb{R}^{W \times H}$ stacks all targets. The local forecast is then:

\begin{equation}
\hat{\mathbf{y}}_{t+1}^{\text{local}} = (\mathbf{W}_t^*)^\top \boldsymbol{\phi}(\mathbf{x}_{t+1})
\end{equation}

\subsection{Adaptive Weighting Mechanism}

To combine predictions from the foundation model $\hat{\mathbf{y}}_t^{\text{FM}} = f_{\text{FM}}(\mathbf{x}_t)$ and the local forecaster $\hat{\mathbf{y}}_t^{\text{local}}$, we employ an adaptive weighting scheme based on recent performance.

We maintain deques of recent residuals:

\begin{align}
\mathcal{R}_t^{\text{FM}} &= \{|\mathbf{y}_{t-M+1} - \hat{\mathbf{y}}_{t-M+1}^{\text{FM}}|, \ldots, |\mathbf{y}_t - \hat{\mathbf{y}}_t^{\text{FM}}|\} \\
\mathcal{R}_t^{\text{local}} &= \{|\mathbf{y}_{t-M+1} - \hat{\mathbf{y}}_{t-M+1}^{\text{local}}|, \ldots, |\mathbf{y}_t - \hat{\mathbf{y}}_t^{\text{local}}|\}
\end{align}

where $M$ is the memory size. We compute exponentially-weighted average errors:

\begin{equation}
e_t^{\text{FM}} = \sum_{i=t-M+1}^{t} w_i \cdot \text{MAE}(\mathbf{y}_i, \hat{\mathbf{y}}_i^{\text{FM}}), \quad e_t^{\text{local}} = \sum_{i=t-M+1}^{t} w_i \cdot \text{MAE}(\mathbf{y}_i, \hat{\mathbf{y}}_i^{\text{local}})
\end{equation}

where the time-decayed weights are:

\begin{equation}
w_i = \frac{\beta^{t-i}}{\sum_{j=t-M+1}^{t} \beta^{t-j}}, \quad \beta \in (0, 1]
\end{equation}

The parameter $\beta$ controls the decay rate (e.g., $\beta=0.9$ emphasizes recent observations). The combination weights are computed via inverse error weighting:

\begin{align}
s^{\text{FM}} &= \frac{1}{e_t^{\text{FM}} + \epsilon}, \quad s^{\text{local}} = \frac{1}{e_t^{\text{local}} + \epsilon} \\
w_t^{\text{FM}} &= \frac{s^{\text{FM}}}{s^{\text{FM}} + s^{\text{local}}}, \quad w_t^{\text{local}} = \frac{s^{\text{local}}}{s^{\text{FM}} + s^{\text{local}}}
\end{align}

where $\epsilon > 0$ is a small constant for numerical stability. The final prediction is:

\begin{equation}
\hat{\mathbf{y}}_{t+1} = w_t^{\text{FM}} \cdot \hat{\mathbf{y}}_{t+1}^{\text{FM}} + w_t^{\text{local}} \cdot \hat{\mathbf{y}}_{t+1}^{\text{local}}
\end{equation}

\subsection{Conformal Prediction}

To quantify uncertainty, we employ adaptive conformal prediction~\cite{gibbs2021adaptive}, which provides distribution-free coverage guarantees even under distribution shift.

\subsubsection{Conformalized Quantile Regression}

Let $\hat{\mathbf{y}}_t$ denote the point forecast (from FM, local, or combined predictor). We maintain a calibration set of recent absolute residuals:

\begin{equation}
\mathcal{C}_t = \{|y_{t-C+1,h} - \hat{y}_{t-C+1,h}| : h=1,\ldots,H\} \cup \cdots \cup \{|y_{t,h} - \hat{y}_{t,h}| : h=1,\ldots,H\}
\end{equation}

where $C$ is the calibration window size. The $(1-\alpha)$-quantile of these residuals is:

\begin{equation}
q_t(1-\alpha) = \text{Quantile}(\mathcal{C}_t, 1-\alpha)
\end{equation}

The prediction interval at time $t+1$ is constructed as:

\begin{equation}
[l_{t+1,h}, u_{t+1,h}] = [\hat{y}_{t+1,h} - q_t(1-\alpha), \hat{y}_{t+1,h} + q_t(1-\alpha)], \quad h=1,\ldots,H
\end{equation}

\subsubsection{Coverage Guarantee}

Under exchangeability, conformal prediction guarantees that:

\begin{equation}
\mathbb{P}(y_{t+1,h} \in [l_{t+1,h}, u_{t+1,h}]) \geq 1 - \alpha
\end{equation}

In practice, for time series, we employ a rolling window approach to adapt to distribution shifts, trading theoretical guarantees for empirical robustness.

\subsection{Complete System}

Algorithm~\ref{alg:adapts} summarizes the complete AdapTS system with conformal prediction.

\begin{algorithm}[t]
\caption{AdapTS with Conformal Prediction}
\label{alg:adapts}
\begin{algorithmic}[1]
\REQUIRE Foundation model $f_{\text{FM}}$, context length $L$, horizon $H$, hyperparameters $\lambda, W, M, C, \alpha, \beta$
\REQUIRE Time series $\{y_t\}_{t=1}^T$
\STATE Initialize empty deques: $\mathcal{W} \leftarrow \emptyset$ (window), $\mathcal{R}^{\text{FM}} \leftarrow \emptyset$, $\mathcal{R}^{\text{local}} \leftarrow \emptyset$, $\mathcal{C} \leftarrow \emptyset$ (calibration)
\STATE Initialize weights: $w^{\text{FM}} \leftarrow 0.5$, $w^{\text{local}} \leftarrow 0.5$
\FOR{$t = L$ to $T - H$}
    \STATE $\mathbf{x}_t \leftarrow [y_{t-L+1}, \ldots, y_t]$ \COMMENT{Extract context}
    \STATE $\boldsymbol{\phi}_t \leftarrow |\text{FFT}(\mathbf{x}_t)|_{[0:L/2]}$ \COMMENT{Frequency features}
    \STATE $\hat{\mathbf{y}}_t^{\text{FM}} \leftarrow f_{\text{FM}}(\mathbf{x}_t)$ \COMMENT{Foundation model prediction}
    \IF{$|\mathcal{W}| \geq \min(5, W)$}
        \STATE $\boldsymbol{\Phi} \leftarrow$ stack features in $\mathcal{W}$, $\mathbf{Y} \leftarrow$ stack targets in $\mathcal{W}$
        \STATE $\mathbf{W}^* \leftarrow (\boldsymbol{\Phi}^\top \boldsymbol{\Phi} + \lambda \mathbf{I})^{-1} \boldsymbol{\Phi}^\top \mathbf{Y}$ \COMMENT{Ridge regression}
        \STATE $\hat{\mathbf{y}}_t^{\text{local}} \leftarrow (\mathbf{W}^*)^\top \boldsymbol{\phi}_t$ \COMMENT{Local prediction}
    \ELSE
        \STATE $\hat{\mathbf{y}}_t^{\text{local}} \leftarrow [y_t, \ldots, y_t]$ \COMMENT{Naive forecast}
    \ENDIF
    \STATE $\hat{\mathbf{y}}_t \leftarrow w^{\text{FM}} \cdot \hat{\mathbf{y}}_t^{\text{FM}} + w^{\text{local}} \cdot \hat{\mathbf{y}}_t^{\text{local}}$ \COMMENT{Weighted combination}
    \STATE $q \leftarrow \text{Quantile}(\mathcal{C}, 1-\alpha)$ \COMMENT{Conformal quantile}
    \STATE $\mathbf{l}_t \leftarrow \hat{\mathbf{y}}_t - q$, $\mathbf{u}_t \leftarrow \hat{\mathbf{y}}_t + q$ \COMMENT{Prediction interval}
    \STATE \textbf{Output:} $(\hat{\mathbf{y}}_t, \mathbf{l}_t, \mathbf{u}_t)$
    \STATE
    \STATE \COMMENT{Update phase (after observing $\mathbf{y}_{t+1:t+H}$)}
    \STATE $\mathbf{y}_{\text{true}} \leftarrow [y_{t+1}, \ldots, y_{t+H}]$
    \STATE Add $(\boldsymbol{\phi}_t, \mathbf{y}_{\text{true}})$ to $\mathcal{W}$ (maintain size $W$)
    \STATE Add $|\mathbf{y}_{\text{true}} - \hat{\mathbf{y}}_t^{\text{FM}}|$ to $\mathcal{R}^{\text{FM}}$ (maintain size $M$)
    \STATE Add $|\mathbf{y}_{\text{true}} - \hat{\mathbf{y}}_t^{\text{local}}|$ to $\mathcal{R}^{\text{local}}$ (maintain size $M$)
    \STATE Add $|\mathbf{y}_{\text{true}} - \hat{\mathbf{y}}_t|$ to $\mathcal{C}$ (maintain size $C$)
    \STATE Update $w^{\text{FM}}, w^{\text{local}}$ using Equations (11)-(12) \COMMENT{Adaptive weighting}
\ENDFOR
\end{algorithmic}
\end{algorithm}

\section{Experiments}
\label{sec:experiments}

\subsection{Datasets}

We evaluate on seven stock market datasets obtained via Yahoo Finance, spanning January 2015 to January 2024:

\begin{itemize}
    \item \textbf{Technology}: GOOGL (Alphabet), MSFT (Microsoft)
    \item \textbf{Retail}: WMT (Walmart), COST (Costco)
    \item \textbf{Energy}: USO (United States Oil Fund), CVX (Chevron)
    \item \textbf{Healthcare}: UNH (UnitedHealth Group)
\end{itemize}

These datasets exhibit diverse characteristics: technology stocks show high volatility with growth trends; retail stocks display seasonal patterns; energy commodities exhibit regime shifts driven by geopolitical events; healthcare stocks demonstrate moderate volatility with steady growth. Each time series contains daily closing prices, resulting in approximately 2,260 observations per asset. We use all data for evaluation (split\_ratio=0.0), conducting online learning where the model makes predictions and updates sequentially.

\subsection{Foundation Models}

We evaluate two foundation models:

\begin{enumerate}
    \item \textbf{BaselineFM}: A custom LSTM-based foundation model with 2 layers, 128 hidden units, trained on 5 datasets (SPY, NVDA, GLD, XOM, JNJ) for 50 epochs using MSE loss. This model is trained on financial data and serves as a domain-specific baseline.

    \item \textbf{Chronos-T5-Tiny}~\cite{ansari2024chronos}: Amazon's pre-trained time series foundation model based on T5 architecture. Chronos is trained on a diverse corpus of time series from multiple domains (not specifically financial data), making it an ideal test case for domain transfer.
\end{enumerate}

\subsection{Evaluated Methods}

We compare three configurations:

\begin{enumerate}
    \item \textbf{FM + Conformal}: Foundation model predictions with conformal prediction intervals. This is the zero-shot baseline.

    \item \textbf{AdapTS + Conformal}: Only the local forecaster with conformal prediction, without using the foundation model. This tests whether local adaptation alone is sufficient.

    \item \textbf{FM + AdapTS + Conformal}: The complete system combining foundation model, local forecaster with adaptive weighting, and conformal prediction.
\end{enumerate}

For Chronos, we compare:
\begin{enumerate}
    \item \textbf{Chronos + Conformal}: Zero-shot Chronos with conformal prediction.
    \item \textbf{Chronos + AdapTS + Conformal}: Chronos combined with adaptive local forecasting.
\end{enumerate}

\subsection{Hyperparameters}

Based on hyperparameter tuning experiments (Section~\ref{sec:results}), we use:

\begin{itemize}
    \item Context length: $L = 96$ (approximately 4 months of trading days)
    \item Forecast horizon: $H = 24$ (approximately 1 month)
    \item Ridge regularization: $\lambda = 0.1$
    \item Sliding window size: $W = 5$
    \item Memory size for weighting: $M = 20$
    \item Time decay factor: $\beta = 0.9$
    \item Calibration size: $C = 200$
    \item Miscoverage rate: $\alpha = 0.1$ (targeting 90\% coverage)
\end{itemize}

\subsection{Evaluation Metrics}

We evaluate both point forecast accuracy and uncertainty quantification:

\begin{itemize}
    \item \textbf{Mean Absolute Error (MAE)}: $\text{MAE} = \frac{1}{N \cdot H} \sum_{t=1}^{N} \sum_{h=1}^{H} |y_{t,h} - \hat{y}_{t,h}|$

    \item \textbf{Root Mean Squared Error (RMSE)}: $\text{RMSE} = \sqrt{\frac{1}{N \cdot H} \sum_{t=1}^{N} \sum_{h=1}^{H} (y_{t,h} - \hat{y}_{t,h})^2}$

    \item \textbf{Coverage}: Proportion of true values within prediction intervals:
    \[
    \text{Coverage} = \frac{1}{N \cdot H} \sum_{t=1}^{N} \sum_{h=1}^{H} \mathbb{I}[l_{t,h} \leq y_{t,h} \leq u_{t,h}]
    \]

    \item \textbf{Interval Width}: Average width of prediction intervals:
    \[
    \text{Width} = \frac{1}{N \cdot H} \sum_{t=1}^{N} \sum_{h=1}^{H} (u_{t,h} - l_{t,h})
    \]
\end{itemize}

Ideal methods achieve low MAE/RMSE (accurate point forecasts), coverage near $1-\alpha$ (well-calibrated uncertainty), and narrow interval widths (informative uncertainty estimates).

\subsection{Implementation}

Our implementation is built in Python using NumPy for numerical operations, scikit-learn for ridge regression, PyTorch for the BaselineFM, and the Chronos library for the Chronos model. All experiments were conducted on a standard workstation. Code is available at \texttt{[repository URL to be added]}.

\section{Results}
\label{sec:results}

\subsection{Hyperparameter Sensitivity}

We conduct a comprehensive hyperparameter sensitivity analysis to identify optimal configurations for the AdapTS system and understand the impact of key parameters on performance.

\textbf{Foundation Model Training.} The BaselineFM converges smoothly over 50 epochs on the five training datasets (SPY, NVDA, GLD, XOM, JNJ), reaching a final training loss of 0.042 (Figure~\ref{fig:optimization}, top left). This pretrained model serves as the frozen foundation model for all subsequent experiments.

\textbf{Grid Search Methodology.} We perform a focused grid search over three critical AdapTS hyperparameters using SPY as the validation dataset (400 samples):
\begin{itemize}
    \item Window size: $W \in \{5, 10, 20\}$
    \item Ridge regularization: $\lambda \in \{0.1, 0.5, 1.0\}$
    \item Time decay factor: $\beta \in \{0.9, 0.95\}$
\end{itemize}
This yields 18 parameter combinations. We fix $\alpha = 0.1$ (targeting 90\% coverage), memory size $M = 20$, and calibration size $C = 200$.

\textbf{Optimal Parameters.} The grid search identifies the following best configuration:
\begin{equation}
W^* = 5, \quad \lambda^* = 0.1, \quad \beta^* = 0.9
\end{equation}
This configuration achieves the lowest validation MAE while maintaining target coverage. Figure~\ref{fig:optimization} (top right) visualizes the parameter sensitivity, revealing that smaller window sizes ($W=5$) enable faster adaptation to distribution shifts, while lighter regularization ($\lambda=0.1$) prevents over-smoothing without sacrificing stability.

\textbf{Training Set Performance.} Using the optimal parameters, we evaluate on all five training datasets. The system achieves an average MAE of 0.108 with consistent coverage of 89.4\% across datasets. Performance varies by asset class: technology (NVDA) and energy (XOM) stocks show higher MAE (0.133 and 0.217) due to greater volatility, while index funds (SPY) and commodities (GLD) exhibit lower MAE (0.055 and 0.065).

\textbf{Test Set Generalization.} Critically, we evaluate the same parameters on seven unseen test datasets from different sectors (GOOGL, MSFT, WMT, COST, USO, CVX, UNH). The system achieves an average MAE of 0.074---\textit{lower than the training set}---with coverage of 89.5\%. This superior test performance demonstrates robust generalization and suggests that the optimal parameters are not overfit to the training data. The best-performing test assets are USO (MAE = 0.045) and WMT (MAE = 0.052), while the most challenging is CVX (MAE = 0.184).

\textbf{Baseline Comparison.} We compare against FM + Conformal (foundation model with conformal prediction only, no adaptation). The baseline exhibits catastrophic failure on test datasets: average MAE of 0.589 (8× higher than AdapTS) and coverage of only 21-27\% (severely miscalibrated). Individual baselines range from MAE = 0.128 (USO) to MAE = 2.120 (CVX), with UNH showing near-zero coverage (5\%). The full AdapTS system achieves an overall improvement of \textbf{89.5\% MAE reduction} compared to the baseline (Figure~\ref{fig:optimization}, bottom).

\textbf{Sensitivity Patterns.} Extended experiments with broader parameter ranges ($W \in \{5, 10, 15, 20, 30, 50\}$, $\lambda \in \{0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0\}$) reveal non-linear relationships:
\begin{itemize}
    \item \textit{Window size}: Performance degrades for $W < 5$ (insufficient data) and $W > 20$ (slow adaptation). $W=5$ provides optimal balance between responsiveness and stability.
    \item \textit{Ridge regularization}: Very small $\lambda < 0.1$ leads to overfitting and high variance, while large $\lambda > 1.0$ causes over-smoothing. $\lambda=0.1$ is robust across diverse market conditions.
    \item \textit{Time decay}: Stronger decay ($\beta=0.9$) emphasizes recent performance in ensemble weighting, improving adaptability during regime shifts.
\end{itemize}

\textbf{Key Insight.} The hyperparameter analysis demonstrates that AdapTS transforms an underperforming foundation model into a highly accurate forecasting system through effective online adaptation. The consistent near-90\% coverage across all configurations validates the robustness of conformal prediction, while the dramatic MAE improvements highlight the critical importance of local adaptation for handling distribution shifts in financial time series.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{optimization_focused_results.png}
    \caption{Hyperparameter tuning results. Top left: Foundation model training loss converges smoothly over 50 epochs, reaching final loss of 0.042. Top right: Grid search results showing MAE across 18 parameter combinations. Bottom left: Performance comparison across five training datasets (average MAE: 0.108) and seven unseen test datasets (average MAE: 0.074). Bottom right: AdapTS vs. FM+Conformal baseline, demonstrating 89.5\% MAE reduction and dramatic coverage improvement from 21-27\% to 89.5\%.}
    \label{fig:optimization}
\end{figure}

\subsection{Three-Method Comparison: BaselineFM}

Figure~\ref{fig:comparison} presents a comprehensive comparison of the three methods using the BaselineFM across all seven datasets.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{summary_comparison.png}
    \caption{Comparison of FM+Conf, AdapTS+Conf, and FM+AdapTS+Conf across seven stock datasets. All methods achieve target 90\% coverage, but AdapTS-based approaches provide substantially lower errors and narrower prediction intervals.}
    \label{fig:comparison}
\end{figure}

\textbf{Coverage (Top-left):} All three methods achieve approximately 90\% coverage across all datasets, closely matching the target $1-\alpha=0.9$. This demonstrates that conformal prediction provides reliable uncertainty quantification regardless of the underlying point forecaster.

\textbf{Interval Width (Top-right):} FM + Conformal produces significantly wider intervals (0.3-0.8) compared to AdapTS-based methods (0.1-0.25). This is expected: poor point forecasts lead to larger residuals, inflating the conformal quantile. AdapTS + Conformal and FM + AdapTS + Conformal produce similarly narrow intervals, with the full system slightly wider on some datasets (GOOGL, USO, CVX).

\textbf{MAE (Bottom-left):} FM + Conformal exhibits 2-8× higher MAE than AdapTS-based methods. Energy stocks (USO, CVX) show the largest gaps, with FM + Conformal MAE exceeding 0.18 while AdapTS methods achieve $<0.06$. AdapTS + Conformal and FM + AdapTS + Conformal perform nearly identically, with differences typically $<0.01$.

\textbf{RMSE (Bottom-right):} Similar patterns emerge for RMSE, with FM + Conformal showing 2-5× higher values than AdapTS methods. The full system shows marginal improvements over AdapTS-only on GOOGL, USO, and CVX ($\sim 10-15\%$).

\textbf{Key Insight:} The foundation model alone struggles with these datasets, but adding AdapTS dramatically improves performance. Surprisingly, AdapTS + Conformal performs almost as well as the full system, suggesting that local adaptation captures most of the predictive signal.

\subsection{Chronos Evaluation: Domain Transfer}

Figure~\ref{fig:chronos} shows results for Chronos, a domain-agnostic model not trained on stock data.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{chronos_summary_comparison.png}
    \caption{Chronos (domain-agnostic FM) with and without AdapTS. Even without domain-specific training, combining Chronos with AdapTS provides 60-70\% MAE reduction while maintaining 90\% coverage and significantly narrower intervals.}
    \label{fig:chronos}
\end{figure}

\textbf{Coverage:} Both methods maintain $\sim 90\%$ coverage, confirming conformal prediction's robustness across different base models.

\textbf{Interval Width:} Chronos + AdapTS + Conformal produces 2-3× narrower intervals than Chronos + Conformal across all datasets. The gap is largest for energy stocks (USO: 0.67 vs 0.23; CVX: 0.54 vs 0.20).

\textbf{MAE:} Chronos + AdapTS achieves 60-70\% MAE reduction across datasets. For example:
\begin{itemize}
    \item GOOGL: 0.100 → 0.036 (64\% reduction)
    \item USO: 0.175 → 0.057 (67\% reduction)
    \item CVX: 0.140 → 0.049 (65\% reduction)
\end{itemize}

\textbf{RMSE:} Similar reductions are observed, with Chronos + AdapTS achieving 60-65\% lower RMSE.

\textbf{Key Insight:} AdapTS provides substantial value even for domain-agnostic foundation models, enabling effective domain transfer without retraining. This suggests that AdapTS captures local patterns complementary to the general representations learned by Chronos.

\subsection{Temporal Analysis}

Figures~\ref{fig:coverage_time} and~\ref{fig:width_time} show coverage and interval width evolution over time for the three-method comparison.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{coverage_comparison_all_datasets.png}
    \caption{Coverage over time for all three methods across seven datasets. All methods maintain stable coverage around the 90\% target (red dashed line) throughout the evaluation period.}
    \label{fig:coverage_time}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{width_comparison_all_datasets.png}
    \caption{Interval width over time. FM + Conformal (blue) produces consistently wider intervals than AdapTS-based methods (red/green), which track each other closely.}
    \label{fig:width_time}
\end{figure}

\textbf{Coverage Stability:} All methods maintain relatively stable coverage around 90\% throughout the 2,000+ timestep evaluation period. Some variance is visible, particularly in the early phase during calibration warmup, but coverage quickly stabilizes. This demonstrates the robustness of adaptive conformal prediction under distribution shift.

\textbf{Width Dynamics:} FM + Conformal shows high variance in interval width, reflecting its struggle to track local patterns. In contrast, AdapTS-based methods exhibit smoother, narrower intervals that adapt more gracefully to changing volatility. Occasional spikes in all methods correspond to periods of high market volatility (e.g., timesteps 1000-1500 likely capture COVID-19 market turbulence in 2020).

\subsection{Error Evolution}

Figures~\ref{fig:mae_time} and~\ref{fig:rmse_time} show MAE and RMSE over time.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{mae_comparison_all_datasets.png}
    \caption{MAE over time. FM + Conformal (blue) exhibits much higher and more variable errors than AdapTS-based methods (red/green), which perform nearly identically.}
    \label{fig:mae_time}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{rmse_comparison_all_datasets.png}
    \caption{RMSE over time, showing similar patterns to MAE. AdapTS-based methods adapt smoothly to changing dynamics while FM + Conformal struggles.}
    \label{fig:rmse_time}
\end{figure}

\textbf{Adaptation Dynamics:} The most striking pattern is the consistent gap between FM + Conformal and AdapTS-based methods. The foundation model alone fails to adapt to dataset-specific patterns, maintaining high errors throughout. In contrast, AdapTS + Conformal and FM + AdapTS + Conformal track each other closely, demonstrating effective online adaptation.

\textbf{Regime Shifts:} All methods show increased errors during specific periods (e.g., timesteps 500-700, 1200-1400), likely corresponding to market regime changes (oil price crashes, pandemic volatility, etc.). However, AdapTS-based methods recover more quickly, suggesting their online learning mechanism helps them adapt to new regimes.

\subsection{Chronos Temporal Analysis}

Figure~\ref{fig:chronos_width} shows interval width evolution for Chronos with and without AdapTS.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{chronos_width_comparison.png}
    \caption{Interval width over time for Chronos. Adding AdapTS (green) produces consistently narrower, more stable intervals compared to Chronos alone (blue).}
    \label{fig:chronos_width}
\end{figure}

The gap between Chronos + Conformal and Chronos + AdapTS + Conformal remains remarkably consistent over time, demonstrating that the benefits of local adaptation persist even as market conditions evolve. This is particularly impressive given that Chronos has no domain-specific knowledge of financial markets.

\section{Discussion}
\label{sec:discussion}

\subsection{Key Findings}

Our experiments reveal several important insights:

\textbf{1. Local adaptation is highly effective.} AdapTS + Conformal achieves near-optimal performance without foundation model guidance, suggesting that local patterns (captured via ridge regression on FFT features) are sufficient for these datasets. This challenges the assumption that large-scale pre-training is always necessary.

\textbf{2. Foundation models provide marginal gains.} The full FM + AdapTS + Conformal system shows only modest improvements (5-15\%) over AdapTS alone. However, this may reflect limitations of our BaselineFM rather than foundation models in general. Larger, more sophisticated FMs (e.g., TimeGPT with billions of parameters) might provide greater benefits.

\textbf{3. Domain transfer works with adaptation.} Chronos, despite lacking financial domain knowledge, achieves excellent performance when combined with AdapTS (60-70\% error reduction). This demonstrates that domain-agnostic FMs can be effectively specialized through lightweight online learning, avoiding expensive retraining.

\textbf{4. Conformal prediction is robust.} All methods maintain $\sim 90\%$ coverage across diverse datasets and market conditions, validating conformal prediction's reliability for time series. The adaptive calibration window successfully handles distribution shift.

\textbf{5. Narrow intervals with coverage.} AdapTS-based methods achieve the "best of both worlds": accurate point forecasts lead to smaller residuals, which in turn yield narrower prediction intervals while maintaining coverage. This is crucial for decision-making.

\subsection{Why Does AdapTS Work?}

Several factors explain AdapTS's effectiveness:

\textbf{Frequency-domain features:} FFT captures periodic patterns, trends, and spectral characteristics that are highly informative for financial time series. Unlike raw values, frequency features are more robust to level shifts.

\textbf{Regularized regression:} Ridge regression with appropriate regularization ($\lambda=0.1$) balances fitting recent data with preventing overfitting to noise, especially critical given the small window size ($W=5$).

\textbf{Online adaptation:} The sliding window mechanism enables continuous learning, allowing the model to track non-stationarity and regime shifts. This is essential for financial data, where distributions evolve over time.

\textbf{Adaptive weighting:} The exponentially-weighted combination of FM and local predictions dynamically adjusts to their relative performance, leveraging the strengths of each component.

\subsection{Limitations}

Several limitations should be acknowledged:

\textbf{Dataset scope:} We focus on stock market data, which exhibits specific characteristics (non-stationarity, volatility clustering, etc.). Generalization to other domains (e.g., weather, healthcare, manufacturing) requires further study.

\textbf{Forecast horizon:} Our experiments use $H=24$ (1 month), which is relatively short. Longer horizons may reduce AdapTS's effectiveness as local patterns become less informative.

\textbf{Foundation model scale:} Our BaselineFM is relatively small (128 hidden units, 2 layers). Larger FMs with billions of parameters might show different tradeoffs.

\textbf{Computational cost:} While AdapTS is lightweight (ridge regression has closed-form solution), the combined system requires both FM inference and local model updates at each timestep. For very high-frequency applications, this may be prohibitive.

\textbf{Calibration window size:} We use a fixed calibration size $C=200$. Adaptive selection based on detected distribution shifts could improve performance.

\subsection{Practical Implications}

Our findings have important implications for practitioners:

\textbf{Start with local adaptation:} For many time series tasks, especially in well-behaved domains, local adaptation alone (AdapTS + Conformal) may be sufficient, avoiding the complexity and cost of deploying large foundation models.

\textbf{Use FMs for domain transfer:} When transferring to new domains with limited data, combining a domain-agnostic FM (e.g., Chronos) with AdapTS provides a powerful approach that leverages general representations while adapting to local patterns.

\textbf{Prioritize uncertainty quantification:} Conformal prediction adds minimal overhead while providing reliable coverage guarantees. It should be standard practice for production forecasting systems.

\textbf{Tune hyperparameters:} Window size $W$ and regularization $\lambda$ significantly impact performance. Cross-validation on a held-out calibration set is recommended.

\subsection{Future Directions}

Several promising research directions emerge:

\textbf{Multivariate extension:} Our work focuses on univariate forecasting. Extending AdapTS to multivariate settings with cross-series dependencies could improve performance.

\textbf{Deeper integration:} Rather than treating FM and local forecaster as separate modules, end-to-end training of an integrated system could learn better feature representations and weighting strategies.

\textbf{Interpretability:} The FFT features and ridge regression weights provide a degree of interpretability. Developing tools to explain which frequency components drive forecasts could enhance trust.

\textbf{Distribution shift detection:} Explicitly detecting regime shifts and triggering reinitialization of the local model could improve adaptation to abrupt changes.

\textbf{Conformal refinements:} Recent advances in conformal prediction (e.g., conditional coverage, online learning of quantile estimators) could further improve uncertainty quantification.

\textbf{Broader evaluation:} Testing on diverse domains (energy, healthcare, climate, etc.) with different data characteristics would strengthen generalization claims.

\section{Conclusion}
\label{sec:conclusion}

This paper presents a comprehensive evaluation of AdapTS, a lightweight method for adapting time series foundation models through online learning, combined with conformal prediction for uncertainty quantification. Through extensive experiments on seven stock market datasets using both domain-specific and domain-agnostic foundation models, we demonstrate:

\begin{enumerate}
    \item \textbf{Local adaptation is highly effective}, with AdapTS + Conformal achieving near-optimal performance without foundation model guidance.

    \item \textbf{Domain transfer works}: Chronos + AdapTS achieves 60-70\% MAE reduction on financial data despite Chronos lacking domain-specific training.

    \item \textbf{Conformal prediction is robust}, consistently achieving $\sim 90\%$ coverage across all methods and datasets.

    \item \textbf{AdapTS provides narrow intervals with coverage}, the ideal combination for practical decision-making.
\end{enumerate}

Our findings suggest that lightweight online adaptation methods can significantly enhance the practical utility of foundation models for time series forecasting, particularly in domains requiring reliable uncertainty quantification. We hope this work encourages further research into adaptive forecasting systems that combine the strengths of large-scale pre-training with targeted online learning.

\section*{Acknowledgments}

This work is based on the AdapTS method proposed by Liu et al.~\cite{liu2025adapts}. We thank the authors for their foundational contributions to adaptive time series forecasting.

\begin{thebibliography}{99}

\bibitem{liu2025adapts}
Liu, Y., et al. (2025).
\textit{AdapTS: Lightweight Adaptation for Time Series Foundation Models}.
arXiv preprint arXiv:2502.12920.

\bibitem{zhou2021informer}
Zhou, H., et al. (2021).
\textit{Informer: Beyond efficient transformer for long sequence time-series forecasting}.
AAAI Conference on Artificial Intelligence.

\bibitem{wu2021autoformer}
Wu, H., et al. (2021).
\textit{Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting}.
NeurIPS.

\bibitem{zhou2022fedformer}
Zhou, T., et al. (2022).
\textit{FEDformer: Frequency enhanced decomposed transformer for long-term series forecasting}.
ICML.

\bibitem{garza2023timegpt}
Garza, A., \& Mergenthaler-Canseco, M. (2023).
\textit{TimeGPT-1}.
arXiv preprint arXiv:2310.03589.

\bibitem{rasul2023lag}
Rasul, K., et al. (2023).
\textit{Lag-Llama: Towards foundation models for time series forecasting}.
arXiv preprint arXiv:2310.08278.

\bibitem{ansari2024chronos}
Ansari, A. F., et al. (2024).
\textit{Chronos: Learning the language of time series}.
arXiv preprint arXiv:2403.07815.

\bibitem{hyndman2008forecasting}
Hyndman, R. J., \& Athanasopoulos, G. (2008).
\textit{Forecasting: principles and practice}.
OTexts.

\bibitem{box2015time}
Box, G. E., Jenkins, G. M., Reinsel, G. C., \& Ljung, G. M. (2015).
\textit{Time series analysis: forecasting and control}.
John Wiley \& Sons.

\bibitem{kalman1960new}
Kalman, R. E. (1960).
\textit{A new approach to linear filtering and prediction problems}.
Journal of Basic Engineering, 82(1), 35-45.

\bibitem{hadsell2020embracing}
Hadsell, R., Rao, D., Rusu, A. A., \& Pascanu, R. (2020).
\textit{Embracing change: Continual learning in deep neural networks}.
Trends in Cognitive Sciences, 24(12), 1028-1040.

\bibitem{finn2017model}
Finn, C., Abbeel, P., \& Levine, S. (2017).
\textit{Model-agnostic meta-learning for fast adaptation of deep networks}.
ICML.

\bibitem{rasmussen2006gaussian}
Rasmussen, C. E., \& Williams, C. K. I. (2006).
\textit{Gaussian processes for machine learning}.
MIT Press.

\bibitem{gal2016dropout}
Gal, Y., \& Ghahramani, Z. (2016).
\textit{Dropout as a Bayesian approximation: Representing model uncertainty in deep learning}.
ICML.

\bibitem{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., \& Blundell, C. (2017).
\textit{Simple and scalable predictive uncertainty estimation using deep ensembles}.
NeurIPS.

\bibitem{vovk2005algorithmic}
Vovk, V., Gammerman, A., \& Shafer, G. (2005).
\textit{Algorithmic learning in a random world}.
Springer.

\bibitem{shafer2008tutorial}
Shafer, G., \& Vovk, V. (2008).
\textit{A tutorial on conformal prediction}.
Journal of Machine Learning Research, 9, 371-421.

\bibitem{xu2021conformal}
Xu, C., \& Xie, Y. (2021).
\textit{Conformal prediction interval for dynamic time-series}.
ICML.

\bibitem{zaffran2022adaptive}
Zaffran, M., et al. (2022).
\textit{Adaptive conformal predictions for time series}.
ICML.

\bibitem{gibbs2021adaptive}
Gibbs, I., \& Candes, E. (2021).
\textit{Adaptive conformal inference under distribution shift}.
NeurIPS.

\bibitem{nie2022time}
Nie, Y., et al. (2022).
\textit{A time series is worth 64 words: Long-term forecasting with transformers}.
ICLR.

\bibitem{das2023decoder}
Das, A., et al. (2023).
\textit{Long-term forecasting with TiDE: Time-series dense encoder}.
arXiv preprint arXiv:2304.08424.

\end{thebibliography}

\end{document}
